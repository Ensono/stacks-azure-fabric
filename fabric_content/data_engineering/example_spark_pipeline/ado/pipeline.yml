name: "0.0$(Rev:.r)"

trigger:
  paths:
    include:
      - fabric_content/data_engineering/example_spark_pipeline/*
  branches:
    include:
      - main

pr:
  paths:
    include:
      - fabric_content/data_engineering/example_spark_pipeline/*
  branches:
    include:
      - main

parameters:
  - name: deploy
    type: boolean
    default: true
    displayName: Deploy Pipeline
  - name: destroy
    type: boolean
    default: false
    displayName: Destroy Pipeline [DANGEROUS]
  - name: environments
    displayName: List of Environments with their deployment dependencies
    type: object
    default:
      - name: test
        dependsOn: run_pre_deploy_tests
        condition: and(succeeded(), or(eq(variables.isPR, true), eq(variables.isManual, true)))
      - name: uat
        dependsOn: run_pre_deploy_tests
        condition: and(succeeded(), eq(variables.isMainBranch, true))
      - name: prod
        dependsOn: uat
        condition: and(succeeded(), eq(variables.isMainBranch, true))

variables:
  - name: python_version
    value: "3.12"
  - name: pipeline_name
    value: example_spark_pipeline
  - name: workspace_type
    value: data_engineering
  - name: isPR
    value: $[eq(variables['Build.Reason'], 'PullRequest')]
  - name: isMainBranch
    value: $[eq(variables['Build.SourceBranch'], 'refs/heads/main')]
  - name: isManual
    value: $[eq(variables['Build.Reason'], 'Manual')]
  # Terraform state storage
  - name: tf_state_key
    value: example_spark_pipeline
  - name: tf_state_rg
    value: stacks-terraform-state
  - name: tf_state_storage
    value: stacksstatehjfis
  - name: tf_state_container
    value: tfstate
  - name: test_src
    value: "data_engineering/$(pipeline_name)/spark_job/tests"

  # Dependency versions
  - name: EirctlVersion
    value: 0.5.7

  - name: pool_vm_image
    value: ubuntu-24.04

stages:
  - stage: prelim
    displayName: Preliminaries

    jobs:
      - job: version_number
        displayName: Set Build Number
        pool:
          vmImage: $(pool_vm_image)

        steps:
          - template: ../../../../build/ado/templates/setup.yml
            parameters:
              EirctlVersion: $(EirctlVersion)

          # Update the build number
          - task: Bash@3
            displayName: Set Build Number
            inputs:
              targetType: inline
              script: |
                eirctl build:number

  - stage: run_pre_deploy_tests
    displayName: Run Tests
    dependsOn: prelim
    jobs:
      - job: run_pre_deploy_tests
        displayName: Run Tests
        pool:
          vmImage: $(pool_vm_image)

        steps:
          - template: ../../../../build_de/workload-pre-deploy-testing.yml
            parameters:
              pythonVersion: $(python_version)
              workingDirectory: "./fabric_content"
              unitTestLocation: "./$(test_src)/unit"
              componentTestLocation: "./$(test_src)/component"
              skipComponentTests: false

  - ${{ each environment in parameters.environments }}:
    - stage: ${{ environment.name }}
      displayName: Deploy ${{ environment.name }}
      dependsOn:
        - ${{ environment.dependsOn }}
      condition: ${{ environment.condition }}
      variables:
        - group: azure-sp-creds
        - group: fabric-${{ environment.name }}-outputs
        - name: FABRIC_TENANT_ID
          value: $(ARM_TENANT_ID)
        - name: FABRIC_CLIENT_ID
          value: $(ARM_CLIENT_ID)
        - name: FABRIC_CLIENT_SECRET
          value: $(ARM_CLIENT_SECRET)
        - name: TF_FILE_LOCATION
          value: fabric_content/$(workspace_type)/$(pipeline_name)/terraform
        - name: ENV_NAME
          value: ${{ environment.name }}

      jobs:
        - job: upload_python
          displayName: Upload Python Scripts
          pool:
            vmImage: $(pool_vm_image)

          steps:
            - template: ../../../../build_de/upload-to-onelake.yml
              parameters:
                pythonVersion: $(python_version)
                workingDirectory: "fabric_content"
                uploadDirectory: "$(workspace_type)/$(pipeline_name)/spark_job"
                fileExtension: ".py"

        - job: deploy_terraform
          displayName: Terraform Stages
          pool:
            vmImage: $(pool_vm_image)

          steps:
            - template: ../../../../build/ado/templates/setup.yml
              parameters:
                EirctlVersion: $(EirctlVersion)

            - task: Bash@3
              displayName: Terraform Init
              inputs:
                targetType: inline
                script: |
                  eirctl infra:init
              env:
                TF_BACKEND_INIT: key=$(tf_state_key)_$(ENV_NAME),container_name=$(tf_state_container),storage_account_name=$(tf_state_storage),resource_group_name=$(tf_state_rg)

            # Configure the variables for Terraform
            - task: Bash@3
              displayName: Terraform Variables
              inputs:
                targetType: inline
                script: |
                  eirctl infra:vars
              env:
                TF_VAR_engineering_workspace_id: $(engineering_workspace_id)
                TF_VAR_engineering_lakehouse_id: $(engineering_lakehouse_id)
                TF_VAR_silver_workspace_id: $(storage_silver_workspace_id)
                TF_VAR_silver_lakehouse_id: $(storage_silver_lakehouse_id)
                TF_VAR_gold_workspace_id: $(storage_gold_example_workspace_id)
                TF_VAR_gold_lakehouse_id: $(storage_gold_example_lakehouse_id)
                TF_VAR_environment: $(ENV_NAME)

            - ${{ if eq(parameters.destroy, true) }}:
              - task: Bash@3
                displayName: Terraform Destroy Plan
                inputs:
                  targetType: inline
                  script: |
                    eirctl infra:destroy:plan

              - task: Bash@3
                displayName: Terraform Destroy Apply
                inputs:
                  targetType: inline
                  script: |
                    eirctl infra:destroy:apply

            - ${{ if eq(parameters.deploy, true) }}:
              - task: Bash@3
                displayName: Terraform Plan
                inputs:
                  targetType: inline
                  script: |
                    eirctl infra:plan

              - task: Bash@3
                displayName: Terraform Apply
                inputs:
                  targetType: inline
                  script: |
                    eirctl infra:apply

        - job: run_e2e_tests
          displayName: Run E2E Tests
          dependsOn: deploy_terraform
          pool:
            vmImage: $(pool_vm_image)

          steps:
            - template: ../../../../build_de/workload-post-deploy-testing.yml
              parameters:
                pythonVersion: $(python_version)
                workingDirectory: "./fabric_content"
                endToEndTestLocation: "./$(test_src)/end_to_end"
                skipEndToEndTests: false
                fabricTenantId: $(ARM_TENANT_ID)
                fabricClientId: $(ARM_CLIENT_ID)
                fabricClientSecret: $(ARM_CLIENT_SECRET)
                engineeringWorkspaceId: $(engineering_workspace_id)
                goldWorkspaceId: $(storage_goldexample_workspace_id)
                goldLakehouseId: $(storage_goldexample_lakehouse_id)
